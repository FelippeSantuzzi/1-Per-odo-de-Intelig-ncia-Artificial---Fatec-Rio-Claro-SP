{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvycq4PyME3AD3l7zGhO7Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelippeSantuzzi/1-Per-odo-de-Intelig-ncia-Artificial---Fatec-Rio-Claro-SP/blob/main/Chat_bot_CAF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyBpgiHtyIwX",
        "outputId": "00f1b87a-f8c0-4f43-89ce-8f2cd4b4054d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aula 01"
      ],
      "metadata": {
        "id": "jFUvwKF0_rZi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wXBauYtl0Qb4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importacao da API_KEY"
      ],
      "metadata": {
        "id": "o_azk1jf_4ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')\n"
      ],
      "metadata": {
        "id": "N-6uLVh-3tZS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conexao com o google gemini"
      ],
      "metadata": {
        "id": "kTbfUJi5AEVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0,\n",
        "    api_key=GOOGLE_API_KEY,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "iaV4h_Y67GcJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp_text = llm.invoke(\"Quem é voce?\")\n",
        "print(resp_text.content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_bGfjlLBGC4",
        "outputId": "cca378db-0d00-4fd8-f881-ac35fffd6cdf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu sou um modelo de linguagem grande, treinado pelo Google.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRIAGEM_PROMPT = (\n",
        "    \"Você é um vendedor externo para política de vendas externas da Caf Máquinas. \"\n",
        "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
        "    \"{\\n\"\n",
        "    '  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\\n'\n",
        "    '  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\\n'\n",
        "    '  \"campos_faltantes\": [\"...\"]\\n'\n",
        "    \"}\\n\"\n",
        "    \"Regras:\\n\"\n",
        "    '- **AUTO_RESOLVER**: Perguntas claras sobre questionamento ou procedimentos descritos nas políticas de vendas (Ex: \"Posso utilizar essa maquina para moer quantos quilos de carne\", \"Como funciona o parcelamento de vendas?\").\\n'\n",
        "    '- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda como comprar uma máquina\", \"Tenho uma dúvida geral\").\\n'\n",
        "    '- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção de modo como a máquina trabalha com a moagem de outro tipo de material.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o setor de vendas\".\").'\n",
        "    \"Analise a mensagem e decida a ação mais apropriada.\"\n",
        ")"
      ],
      "metadata": {
        "id": "cqyTI4SAeBdI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, List, Dict\n",
        "\n",
        "class triagemOut(BaseModel):\n",
        "  decisao: Literal[\"AUTO_RESOLVER\",\"PEDIR_INFO\",\"ABRIR_CHAMADO\"]\n",
        "  urgencia: Literal[\"BAIXA\",\"MEDIA\",\"ALTA\"]\n",
        "  campos_faltantes: List[str] = Field(default_factory=list)"
      ],
      "metadata": {
        "id": "oWzUzLVsN_sr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_triagem = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0,\n",
        "    api_key=GOOGLE_API_KEY,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "Yd7jNhFLTh4f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "triagem_chain = llm_triagem.with_structured_output(triagemOut)\n",
        "\n",
        "def triagem(mensagem: str) -> Dict:\n",
        "  saida: TriagemOut = triagem_chain.invoke([\n",
        "      SystemMessage(content=TRIAGEM_PROMPT),\n",
        "      HumanMessage(content=mensagem)\n",
        "  ])\n",
        "\n",
        "  return saida.model_dump()"
      ],
      "metadata": {
        "id": "0LRYJxmWvUun"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testes = [\"posso utilizar essa máquina para moer quantos quilos de carne?\" ,\n",
        "          \"preciso de ajuda como comprar essa máquina\",\n",
        "          \" tenho uma ajuda geral\",\n",
        "          \"por que preciso dessa máquina?\"]\n"
      ],
      "metadata": {
        "id": "z6r4NjiBwyCm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for msg_test in testes:\n",
        "  print(msg_test)\n",
        "  print(triagem(msg_test))\n",
        "  print(f\"pergunta {msg_test}\\n -> Resposta: {triagem(msg_test)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15oTEhcpx8-H",
        "outputId": "17fc09b9-a6b1-4337-dab2-c2e156401acd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "posso utilizar essa máquina para moer quantos quilos de carne?\n",
            "{'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "pergunta posso utilizar essa máquina para moer quantos quilos de carne?\n",
            " -> Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n",
            "preciso de ajuda como comprar essa máquina\n",
            "{'decisao': 'PEDIR_INFO', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "pergunta preciso de ajuda como comprar essa máquina\n",
            " -> Resposta: {'decisao': 'PEDIR_INFO', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n",
            " tenho uma ajuda geral\n",
            "{'decisao': 'PEDIR_INFO', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "pergunta  tenho uma ajuda geral\n",
            " -> Resposta: {'decisao': 'PEDIR_INFO', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n",
            "por que preciso dessa máquina?\n",
            "{'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "pergunta por que preciso dessa máquina?\n",
            " -> Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rU-ItcPuzbef"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "otsX0gfdSjE_"
      }
    }
  ]
}